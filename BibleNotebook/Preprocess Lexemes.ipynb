{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Lexemes\n",
    "\n",
    "Processes the Lexemes YAML file into a standard `lexemes.csv` file.\n",
    "The data is then enhanced with the part of speech based using `morphgnt.csv`.\n",
    "\n",
    "| lexemes.yaml | morphgnt.csv | lexemes.csv |\n",
    "|--------------|--------------|-------------|\n",
    "| pos | | PART_OF_SPEECH_CODE |\n",
    "| full-citation-form | | FULL_CITATION_FORM |\n",
    "| bdag-headword | | BDAG_ENTRY |\n",
    "| danker-entry | | DANKER_ENTRY |\n",
    "| dodson-entry | | DODSON_ENTRY |\n",
    "| mounce-headword | | MOUNCE_ENTRY |\n",
    "| strongs | | STRONGS |\n",
    "| gk | | GK |\n",
    "| dodson-pos | | DODSON_PART_OF_SPEECH_CODE |\n",
    "| gloss | | GLOSS |\n",
    "| mounce-morphcat | | MOUNCE_MORPHCAT |\n",
    "| | PART_OF_SPEECH | PART_OF_SPEECH|\n",
    "\n",
    "## Define File Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE_NAME = \"../BibleCore/Resources/lexemes.yaml\"\n",
    "OUTPUT_FILE_NAME = \"lexemes.csv\"\n",
    "MORPHGNT_CSV = \"morphgnt.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Lexemes File into DataFrame (DF_LEXEMES)\n",
    "\n",
    "Columns:\n",
    "\n",
    "* Part of Speech Code (pos)\n",
    "* Full Citation Form (full-citation-form)\n",
    "* BDAG Entry (bdag-headword)\n",
    "* Danker Entry (danker-entry)\n",
    "* Dodson Entry (dodson-entry)\n",
    "* Mounce Entry (mounce-headword)\n",
    "* Strongs (strongs)\n",
    "* GK (gk)\n",
    "* Dodson Part of Speech Code (dodson-pos)\n",
    "* Gloss (gloss)\n",
    "* Mounce MorphCat (mounce-morphcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "import biblesdk.constants as bc\n",
    "\n",
    "with open(INPUT_FILE_NAME, \"r\", encoding=\"utf-8\") as file:\n",
    "    yaml_data = yaml.safe_load(file)\n",
    "\n",
    "DF_LEXEMES = pd.DataFrame.from_dict(yaml_data, orient=\"index\")\n",
    "DF_LEXEMES.index.name = bc.LEMMA\n",
    "DF_LEXEMES.rename(\n",
    "    columns={\n",
    "        \"pos\": bc.PART_OF_SPEECH_CODE,\n",
    "        \"full-citation-form\": bc.FULL_CITATION_FORM,\n",
    "        \"bdag-headword\": bc.BDAG_ENTRY,\n",
    "        \"danker-entry\": bc.DANKER_ENTRY,\n",
    "        \"dodson-entry\": bc.DODSON_ENTRY,\n",
    "        \"mounce-headword\": bc.MOUNCE_ENTRY,\n",
    "        \"strongs\": bc.STRONGS,\n",
    "        \"gk\": bc.GK,\n",
    "        \"dodson-pos\": bc.DODSON_PART_OF_SPEECH_CODE,\n",
    "        \"gloss\": bc.GLOSS,\n",
    "        \"mounce-morphcat\": bc.MOUNCE_MORPHCAT,\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# print(\"===== DF_LEXEMES\")\n",
    "# print(DF_LEXEMES.__class__.__name__)\n",
    "# print(\"-----\")\n",
    "# pprint(vars(DF_LEXEMES))\n",
    "# print(\"-----\")\n",
    "# pprint(DF_LEXEMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Part of Speech\n",
    "\n",
    "The Part of Speech column is determined using the `morphgnt.csv` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_MORPHGNT = pd.read_csv(MORPHGNT_CSV, index_col=bc.INDEX)\n",
    "GB_LEMMA = DF_MORPHGNT.groupby([bc.LEMMA])\n",
    "\n",
    "morphgnt_parts_of_speech = dict(\n",
    "    [(name[0], group[bc.PART_OF_SPEECH].unique()[0]) for name, group in GB_LEMMA]\n",
    ")\n",
    "\n",
    "DF_LEXEMES[bc.PART_OF_SPEECH] = pd.Series(morphgnt_parts_of_speech)\n",
    "\n",
    "# print(\"===== DF_LEXEMES\")\n",
    "# print(DF_LEXEMES.__class__.__name__)\n",
    "# print(\"-----\")\n",
    "# pprint(vars(DF_LEXEMES))\n",
    "# print(\"-----\")\n",
    "# pprint(DF_LEXEMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write lexemes.csv File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_LEXEMES.to_csv(OUTPUT_FILE_NAME, index_label=bc.LEMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility - Obtain all unique combinations of Part of Speech Code and Dodson Part of Speech Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Part of Speech Code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Dodson Part of Speech Code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9aba2784-9627-4a84-b9cc-d46e478f9b46",
       "rows": [
        [
         "0",
         "A",
         "A",
         "718"
        ],
        [
         "1",
         "A",
         "A,A-NUI",
         "1"
        ],
        [
         "2",
         "A",
         "A,ADV",
         "4"
        ],
        [
         "3",
         "A",
         "A,ADV-C",
         "2"
        ],
        [
         "4",
         "A",
         "A,N:F,N:M",
         "1"
        ],
        [
         "5",
         "A",
         "A-NUI",
         "18"
        ],
        [
         "6",
         "A",
         "ADV-S",
         "1"
        ],
        [
         "7",
         "A",
         "N:F",
         "1"
        ],
        [
         "8",
         "A",
         "N:M",
         "1"
        ],
        [
         "9",
         "A",
         "N:N",
         "1"
        ],
        [
         "10",
         "A/ADV",
         "A",
         "1"
        ],
        [
         "11",
         "A/ADV",
         "ADV",
         "2"
        ],
        [
         "12",
         "A/ADV-C",
         "A",
         "1"
        ],
        [
         "13",
         "A/ADV-C",
         "ADV",
         "1"
        ],
        [
         "14",
         "A/ADV-C",
         "ADV-C",
         "2"
        ],
        [
         "15",
         "A/ADV-C?",
         "ADV",
         "1"
        ],
        [
         "16",
         "A/ADV-S",
         "ADV-S",
         "1"
        ],
        [
         "17",
         "A/ADV-S?",
         "A",
         "1"
        ],
        [
         "18",
         "A/N",
         "A",
         "1"
        ],
        [
         "19",
         "A/N",
         "N:F",
         "7"
        ],
        [
         "20",
         "A/N",
         "N:M",
         "9"
        ],
        [
         "21",
         "A/N",
         "N:N",
         "5"
        ],
        [
         "22",
         "A/RP1",
         "S",
         "1"
        ],
        [
         "23",
         "A/S-2P",
         "S",
         "1"
        ],
        [
         "24",
         "A/S-2S",
         "S",
         "1"
        ],
        [
         "25",
         "A/S1",
         "S",
         "1"
        ],
        [
         "26",
         "C",
         "CONJ",
         "22"
        ],
        [
         "27",
         "C/ADV",
         "ADV",
         "17"
        ],
        [
         "28",
         "C/ADV",
         "ADV,ADV-I",
         "1"
        ],
        [
         "29",
         "C/ADV",
         "ADV-N",
         "1"
        ],
        [
         "30",
         "C/ADV-K",
         "ADV-K",
         "2"
        ],
        [
         "31",
         "C/COND",
         "COND",
         "2"
        ],
        [
         "32",
         "C/COND-K",
         "COND-K",
         "1"
        ],
        [
         "33",
         "C/CONJ-N",
         "CONJ-N",
         "3"
        ],
        [
         "34",
         "C/D",
         "ADV",
         "2"
        ],
        [
         "35",
         "C/PRT",
         "PRT",
         "7"
        ],
        [
         "36",
         "C/PRT-I",
         "PRT-I",
         "1"
        ],
        [
         "37",
         "D",
         "ADV",
         "188"
        ],
        [
         "38",
         "D",
         "ADV,ADV-C",
         "3"
        ],
        [
         "39",
         "D",
         "ADV,V",
         "1"
        ],
        [
         "40",
         "D",
         "ADV-C",
         "3"
        ],
        [
         "41",
         "D",
         "ADV-I",
         "2"
        ],
        [
         "42",
         "D",
         "ADV-N",
         "9"
        ],
        [
         "43",
         "D",
         "ADV-S",
         "2"
        ],
        [
         "44",
         "D/ADV-N",
         "ADV-N",
         "1"
        ],
        [
         "45",
         "D/ADV-S",
         "ADV-S",
         "1"
        ],
        [
         "46",
         "D/ARAM",
         "ARAM,HEB",
         "1"
        ],
        [
         "47",
         "D/CONJ",
         "CONJ",
         "1"
        ],
        [
         "48",
         "D/CONJ-N",
         "CONJ-N",
         "1"
        ],
        [
         "49",
         "D/N",
         "N:F",
         "1"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 111
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Part of Speech Code</th>\n",
       "      <th>Dodson Part of Speech Code</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>A,A-NUI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>A,ADV</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>A,ADV-C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>A,N:F,N:M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>X/INJ</td>\n",
       "      <td>INJ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>X/INJ</td>\n",
       "      <td>INJ,N-OI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>X/PRT-I</td>\n",
       "      <td>PRT-I,PRT-N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>X/V</td>\n",
       "      <td>INJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>X/V</td>\n",
       "      <td>V</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Part of Speech Code Dodson Part of Speech Code  Count\n",
       "0                     A                          A    718\n",
       "1                     A                    A,A-NUI      1\n",
       "2                     A                      A,ADV      4\n",
       "3                     A                    A,ADV-C      2\n",
       "4                     A                  A,N:F,N:M      1\n",
       "..                  ...                        ...    ...\n",
       "106               X/INJ                        INJ      3\n",
       "107               X/INJ                   INJ,N-OI      1\n",
       "108             X/PRT-I                PRT-I,PRT-N      1\n",
       "109                 X/V                        INJ      1\n",
       "110                 X/V                          V      2\n",
       "\n",
       "[111 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB_POS = DF_LEXEMES.groupby([bc.PART_OF_SPEECH_CODE, bc.DODSON_PART_OF_SPEECH_CODE])\n",
    "GB_POS = GB_POS.size()\n",
    "GB_POS = GB_POS.reset_index()\n",
    "GB_POS = GB_POS.rename(columns={0: bc.COUNT})\n",
    "\n",
    "# print(\"===== GB_POS\")\n",
    "# print(GB_POS.__class__.__name__)\n",
    "# print(\"-----\")\n",
    "# pprint(vars(GB_POS))\n",
    "# print(\"-----\")\n",
    "# pprint(GB_POS)\n",
    "\n",
    "GB_POS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
